{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\platform\\self_check.py\u001b[0m in \u001b[0;36mpreload_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m           \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudart_dll_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] 지정된 모듈을 찾을 수 없습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bb2c39210f44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### 라이브러리 ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Perform pre-load sanity checks in order to produce a more actionable error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# than we get from an error during SWIG import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mself_check\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreload_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\platform\\self_check.py\u001b[0m in \u001b[0;36mpreload_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m               \u001b[1;34m\"environment variable. Download and install CUDA %s from \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m               \u001b[1;34m\"this URL: https://developer.nvidia.com/cuda-90-download-archive\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m               % (build_info.cudart_dll_name, build_info.cuda_version_number))\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m       if hasattr(build_info, \"cudnn_dll_name\") and hasattr(\n",
      "\u001b[1;31mImportError\u001b[0m: Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive"
     ]
    }
   ],
   "source": [
    "### 라이브러리 ###\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 하이퍼파라미터 ###\n",
    "input_data_column_cnt = 5  # 입력 데이터의 컬럼 개수\n",
    "output_data_column_cnt = 1  # 결과데이터의 컬럼 개수\n",
    "seq_length = 120  # 시퀀스의 길이(시계열데이터 입력 개수)\n",
    "rnn_cell_hidden_dim = 10  # 각 셀의 (hidden) 출력 크기\n",
    "forget_bias = 1.0  # 망각편향(기본값 1.0)\n",
    "num_stacked_layers = 3  # stacked LSTM layers 개수\n",
    "keep_prob = 1.0  # dropout할 때 keep할 비율\n",
    "epoch_num = 1500  # 에폭 횟수 (학습용 전체 데이터를 몇 회 반복해서 학습할 것인가 입력)\n",
    "learning_rate = 0.05  # 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function ###\n",
    "# Normalization - 입력변수를 정규화함으로써, 학습성과 향상\n",
    "def min_max_scaling(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.min()) / (x_np.max() - x_np.min())\n",
    "\n",
    "\n",
    "# Reverse Normalization - 결과값 확인을 위해 정규화된 값을 역 정규화\n",
    "def reverse_min_max_scaling(org_x, x):\n",
    "    org_x_np = np.asarray(org_x)\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np * (org_x_np.max() - org_x_np.min())) + org_x_np.min()\n",
    "\n",
    "\n",
    "# MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed - 딥러닝 모형의 일정한 결과값을 위해\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Loading ###\n",
    "path = '/'\n",
    "index_file_name = 'kospi.xlsx'\n",
    "encoding = 'euc-kr'  # 문자 인코딩\n",
    "raw_dataframe = pd.read_excel(path + index_file_name, encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_dataframe[['종가','시가','고가','저가','거래량']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preprocessing ###\n",
    "del raw_dataframe['일']  # Date 열 제거\n",
    "\n",
    "# del raw_dataframe['Time'] # Time 열 제거 - 분봉데이터의 경우\n",
    "index_info = raw_dataframe.values[0:].astype(np.float)  # 지수&거래량 문자열을 부동소수점으로 변환\n",
    "\n",
    "# 지수와 거래량 데이터 정규화 - Scale 차이로 인해 별도 정규화\n",
    "index = index_info[:, :-1]\n",
    "norm_index = min_max_scaling(index)\n",
    "\n",
    "volume = index_info[:, -1:]\n",
    "norm_volume = min_max_scaling(volume)\n",
    "\n",
    "# 정규화가 끝난 후 데이터 합치기\n",
    "x = np.concatenate((norm_index, norm_volume), axis=1)\n",
    "\n",
    "# 종속 변수 선정 - 종가지수\n",
    "y = x[:, [-2]]\n",
    "\n",
    "# 입력변수와 종속변수가 들어갈 리스트 생성 후 반복문을 통해 데이터 삽입\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, len(y) - seq_length):\n",
    "    _x = x[i: i + seq_length]\n",
    "    _y = y[i + seq_length]\n",
    "    dataX.append(_x)\n",
    "    dataY.append(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용/테스트용 데이터 생성\n",
    "train_size = int(len(dataY) * 0.8)\n",
    "test_size = len(dataY) - train_size\n",
    "\n",
    "# 데이터를 잘라 학습용 데이터 생성\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "trainY = np.array(dataY[0:train_size])\n",
    "\n",
    "# 데이터를 잘라 테스트용 데이터 생성\n",
    "testX = np.array(dataX[train_size:len(dataX)])\n",
    "testY = np.array(dataY[train_size:len(dataY)])\n",
    "\n",
    "# 텐서플로우 플레이스홀더 생성\n",
    "# 입력 X, 출력 Y를 생성\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, input_data_column_cnt])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# 검증용 측정지표를 산출하기 위한 targets, predictions를 생성\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###모델(LSTM 네트워크) 생성 ###\n",
    "def lstm_cell():\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim,\n",
    "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
    "    if keep_prob < 1.0:\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    return cell\n",
    "\n",
    "\n",
    "# num_stacked_layers개의 층으로 쌓인 Stacked LSTMs 생성\n",
    "stackedLSTMs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
    "multi_cells = tf.contrib.rnn.MultiRNNCell(stackedLSTMs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()\n",
    "\n",
    "# LSTM Cell 연결\n",
    "hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
    "\n",
    "# 과거 여러 거래일의 주가를 이용해서 다음날의 주가 1개를 예측하기때문에 MANY-TO-ONE 형태\n",
    "hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_column_cnt, activation_fn=tf.identity)\n",
    "\n",
    "# 손실함수로 평균제곱오차를 사용한다\n",
    "loss = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "\n",
    "# 최적화함수로 AdamOptimizer를 사용한다\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 학습용 데이터와 테스트용 데이터의 오류 기록을 위한 리스트 생성\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))\n",
    "train_error_summary = []\n",
    "test_error_summary = []\n",
    "test_predict = ''\n",
    "\n",
    "# 텐서플로우 실행을 위한 세션 설정\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습 시작\n",
    "start_time = datetime.datetime.now()  # 시작시간 기록\n",
    "print('학습을 시작합니다')\n",
    "for epoch in range(epoch_num):\n",
    "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
    "    if ((epoch + 1) % 100 == 0) or (epoch == epoch_num - 1):  # 100번째마다 또는 마지막 epoch인 경우\n",
    "        # 학습용데이터로 rmse오차를 구한다\n",
    "        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
    "        train_error = sess.run(rmse, feed_dict={targets: reverse_min_max_scaling(index, trainY),\n",
    "                                                predictions: reverse_min_max_scaling(index, train_predict)})\n",
    "        train_error_summary.append(train_error)\n",
    "\n",
    "        # 테스트용데이터로 rmse오차를 구한다\n",
    "        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
    "        test_error = sess.run(rmse, feed_dict={targets: reverse_min_max_scaling(index, testY),\n",
    "                                               predictions: reverse_min_max_scaling(index, test_predict)})\n",
    "        test_error_summary.append(test_error)\n",
    "\n",
    "        # 현재 오류 출력\n",
    "        print(\"epoch: {}, train_error(A): {}, test_error(B): {}, B-A: {}\".format(epoch + 1, train_error, test_error,\n",
    "                                                                                 test_error - train_error))\n",
    "end_time = datetime.datetime.now()  # 종료시간 기록\n",
    "elapsed_time = end_time - start_time  # 경과시간 기록\n",
    "print('elapsed_time:', elapsed_time)\n",
    "print('elapsed_time per epoch:', elapsed_time / epoch_num)\n",
    "\n",
    "# 정규화된 데이터를 역정규화\n",
    "trainX = reverse_min_max_scaling(index, trainX)\n",
    "trainY = reverse_min_max_scaling(index, trainY)\n",
    "testX = reverse_min_max_scaling(index, testX)\n",
    "testY = reverse_min_max_scaling(index, testY)\n",
    "test_predict = reverse_min_max_scaling(index, test_predict)\n",
    "\n",
    "# LSTM 모형 성능 평가\n",
    "rmse = sqrt(mean_squared_error(testY, test_predict))\n",
    "mape = mean_absolute_percentage_error(testY, test_predict)\n",
    "print(\"rmse:\", rmse)\n",
    "print(\"mape:\", mape)\n",
    "\n",
    "# 결과 (.txt) 생성\n",
    "path = 'C:/Users/CanTuna/Desktop/졸업 논문/'\n",
    "title = ('LSTM' + '_' + str(seq_length) + '_' + str(rnn_cell_hidden_dim) + '_' + str(num_stacked_layers) + '_' + str(\n",
    "    epoch_num) + '_' + str(learning_rate))\n",
    "result = open(path + title + '.txt', 'wt')\n",
    "result.write('testY' + '\\t' + 'test_predict' + '\\n')\n",
    "for i in range(len(testY)):\n",
    "    result.write(str(testY[i][0]) + '\\t' + str(test_predict[i][0]) + '\\n')\n",
    "result.write('Total RMSE: ' + str(rmse) + '\\n')\n",
    "result.write('Total MAPE: ' + str(mape) + '\\n')\n",
    "result.close()\n",
    "\n",
    "# 결과 그래프 출력\n",
    "plt.figure(1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(testY, 'r')\n",
    "plt.plot(test_predict, 'b')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Index')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
